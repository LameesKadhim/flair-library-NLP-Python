{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair library.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHEOsRcLT1jYRWyH1x/MOr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LameesKadhim/flair-library-NLP-Python/blob/main/flair_library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL6J-X8JyC8c"
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu7ZhI_WzKJS"
      },
      "source": [
        "## **Create a Sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh4haVUKzQ9i",
        "outputId": "88f96f48-432c-41c6-ffdd-6a6b77bc6e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# the Sentence objects hold a sentence that we may want to embed or tag\n",
        "from flair.data import Sentence\n",
        "\n",
        "# make a sentence object by passing a whitespace tokenized string\n",
        "sentence = Sentence('the grass is green.')\n",
        "\n",
        "# print the object to see what is in there\n",
        "print(sentence)\n",
        "\n",
        "# using the token id\n",
        "print(sentence.get_token(2))\n",
        "# using the index it self\n",
        "print(sentence[1])\n",
        "\n",
        "for token in sentence:\n",
        "  print(token)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"the grass is green .\"   [− Tokens: 5]\n",
            "Token: 2 grass\n",
            "Token: 2 grass\n",
            "Token: 1 the\n",
            "Token: 2 grass\n",
            "Token: 3 is\n",
            "Token: 4 green\n",
            "Token: 5 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ll7l9wy0snz"
      },
      "source": [
        "## **Adding Tags and labels to Tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fps3Ztnw_Puz"
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.data import Label"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q22BN0KZ1Izv",
        "outputId": "8e74dfb0-f2fb-49e5-b31a-6ee009f3fc43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentence = Sentence('I love the blue sky', use_tokenizer=True)\n",
        "\n",
        "print(sentence)\n",
        "\n",
        "# add a tag to a word in the sentence\n",
        "sentence[3].add_tag('ner', 'color')\n",
        "print('Adding tag to a word')\n",
        "# print the sentence with all tags of this type\n",
        "print(sentence.to_tagged_string())\n",
        "\n",
        "tag: Label = sentence[3].get_tag('ner')\n",
        "print(f'\"{sentence[3]}\" is tagged as \"{tag.value}\" with confidence score \"{tag.score}\"')\n",
        "\n",
        "sentence = Sentence('Germany is the current world cup winner')\n",
        "\n",
        "# add a lable to a sentence\n",
        "print('\\nadd a lable to a sentence')\n",
        "sentence.add_label(str ,value='football')\n",
        "# a sentence can also belong to multiple classes\n",
        "sentence.add_label(str, value= ['football', 'world cup'])\n",
        "\n",
        "print('\\n', sentence, '\\n')\n",
        "for label in sentence.labels:\n",
        "  print(label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"I love the blue sky\"   [− Tokens: 5]\n",
            "Adding tag to a word\n",
            "I love the blue <color> sky\n",
            "\"Token: 4 blue\" is tagged as \"color\" with confidence score \"1.0\"\n",
            "\n",
            "add a lable to a sentence\n",
            "\n",
            " Sentence: \"Germany is the current world cup winner\"   [− Tokens: 7  − Sentence-Labels: {<class 'str'>: [football (1.0), ['football', 'world cup'] (1.0)]}] \n",
            "\n",
            "football (1.0)\n",
            "['football', 'world cup'] (1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrQhFJQ6tICA"
      },
      "source": [
        "## **Named Entity Recognition(NER)**\n",
        "NER is a sub-task of information extraction (IE) that seeks out and categories specified entities in a body or bodies of texts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EX0NW3Btuz6",
        "outputId": "689cb290-bdc7-4932-8bd2-dd450dbd2e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "\n",
        "tagger = SequenceTagger.load('ner')\n",
        "sentence = Sentence('George Washington went to Washington.')\n",
        "# predict NER tags\n",
        "tagger.predict(sentence)\n",
        "# print sentence with predicted tags\n",
        "print('\\n', sentence.to_tagged_string())\n",
        "for entity in sentence.get_spans('ner'):\n",
        "  print('\\n', entity)\n",
        "print('\\n', sentence.to_dict(tag_type='ner'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-01 19:10:32,311 loading file /root/.flair/models/en-ner-conll03-v0.4.pt\n",
            "\n",
            " George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n",
            "\n",
            " Span [1,2]: \"George Washington\"   [− Labels: PER (0.9968)]\n",
            "\n",
            " Span [5]: \"Washington\"   [− Labels: LOC (0.9994)]\n",
            "\n",
            " {'text': 'George Washington went to Washington.', 'labels': [], 'entities': [{'text': 'George Washington', 'start_pos': 0, 'end_pos': 17, 'labels': [PER (0.9968)]}, {'text': 'Washington', 'start_pos': 26, 'end_pos': 36, 'labels': [LOC (0.9994)]}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErvJ8Jakxv26",
        "outputId": "e9803d01-9e9c-43d6-9155-6dc91c90da31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# make a sentence\n",
        "sentence = Sentence('I love Berlin.')\n",
        "\n",
        "# load the NER tagger\n",
        "tagger = SequenceTagger.load('ner')\n",
        "\n",
        "# run NER over sentence\n",
        "tagger.predict(sentence)\n",
        "\n",
        "print('\\n', sentence)\n",
        "print('\\nThe following NER tags are found')\n",
        "\n",
        "# iterate over entities and print\n",
        "for entity in sentence.get_spans('ner'):\n",
        "  print('\\n', entity)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-01 19:11:30,171 loading file /root/.flair/models/en-ner-conll03-v0.4.pt\n",
            "\n",
            " Sentence: \"I love Berlin .\"   [− Tokens: 4  − Token-Labels: \"I love Berlin <S-LOC> .\"]\n",
            "\n",
            "The following NER tags are found\n",
            "\n",
            " Span [3]: \"Berlin\"   [− Labels: LOC (0.9992)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mblR8zlUzCHu"
      },
      "source": [
        "## **Text Classification and prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyXExNWHzL0a",
        "outputId": "5e137d4a-0f0b-4707-ce36-7b71fad6210a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "\n",
        "classifier = TextClassifier.load('en-sentiment')\n",
        "sentence1 = Sentence('This film hurts. It is so bad that I am confused')\n",
        "sentence2 = Sentence('Flair is pretty neat!')\n",
        "# predict NER tags\n",
        "classifier.predict([sentence1, sentence2])\n",
        "\n",
        "# print sentence with predicted labels\n",
        "print('\\nsentence 1 is: {} and sentence 2 is:  {}'.format(sentence1.labels, sentence2.labels))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-01 19:11:48,010 loading file /root/.flair/models/sentiment-en-mix-distillbert_3.1.pt\n",
            "\n",
            "sentence 1 is: [NEGATIVE (1.0)] and sentence 2 is:  [POSITIVE (0.9997)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZQ62_i23vM"
      },
      "source": [
        "## **Word Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOT4GdDm29F-",
        "outputId": "bc91188a-a3df-4843-cf6c-1dd2083846d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# GloVe is an unsupervised learning algorithm for obtaining vector representations for words. \n",
        "# Training is performed on aggregated global word-word co-occurrence statistics from a corpus,\n",
        "# and the resulting representations showcase interesting linear substructures of the word vector space. \n",
        "\n",
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.data import Sentence\n",
        "\n",
        "# init embedding\n",
        "glove_embedding = WordEmbeddings('glove')\n",
        "\n",
        "# create sentence\n",
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# embed a sentence using glove\n",
        "glove_embedding.embed(sentence)\n",
        "\n",
        "# now check out the embedded tokens\n",
        "for token in sentence:\n",
        "  print('\\n', token)\n",
        "  print(token.embedding)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Token: 1 The\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
            "\n",
            " Token: 2 grass\n",
            "tensor([-0.8135,  0.9404, -0.2405, -0.1350,  0.0557,  0.3363,  0.0802, -0.1015,\n",
            "        -0.5478, -0.3537,  0.0734,  0.2587,  0.1987, -0.1433,  0.2507,  0.4281,\n",
            "         0.1950,  0.5346,  0.7424,  0.0578, -0.3178,  0.9436,  0.8145, -0.0824,\n",
            "         0.6166,  0.7284, -0.3262, -1.3641,  0.1232,  0.5373, -0.5123,  0.0246,\n",
            "         1.0822, -0.2296,  0.6039,  0.5541, -0.9610,  0.4803,  0.0022,  0.5591,\n",
            "        -0.1637, -0.8468,  0.0741, -0.6216,  0.0260, -0.5162, -0.0525, -0.1418,\n",
            "        -0.0161, -0.4972, -0.5534, -0.4037,  0.5096,  1.0276, -0.0840, -1.1179,\n",
            "         0.3226,  0.4928,  0.9488,  0.2040,  0.5388,  0.8397, -0.0689,  0.3136,\n",
            "         1.0450, -0.2267, -0.0896, -0.6427,  0.6443, -1.1001, -0.0096,  0.2668,\n",
            "        -0.3230, -0.6065,  0.0479, -0.1664,  0.8571,  0.2335,  0.2539,  1.2546,\n",
            "         0.5472, -0.1980, -0.7186,  0.2076, -0.2587, -0.3650,  0.0834,  0.6932,\n",
            "         0.1574,  1.0931,  0.0913, -1.3773, -0.2717,  0.7071,  0.1872, -0.3307,\n",
            "        -0.2836,  0.1030,  1.2228,  0.8374])\n",
            "\n",
            " Token: 3 is\n",
            "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
            "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
            "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
            "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
            "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
            "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
            "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
            "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
            "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
            "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
            "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
            "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
            "        -0.0442, -1.2969,  0.7622,  0.4635])\n",
            "\n",
            " Token: 4 green\n",
            "tensor([-6.7907e-01,  3.4908e-01, -2.3984e-01, -9.9652e-01,  7.3782e-01,\n",
            "        -6.5911e-04,  2.8010e-01,  1.7287e-02, -3.6063e-01,  3.6955e-02,\n",
            "        -4.0395e-01,  2.4092e-02,  2.8958e-01,  4.0497e-01,  6.9992e-01,\n",
            "         2.5269e-01,  8.0350e-01,  4.9370e-02,  1.5562e-01, -6.3286e-03,\n",
            "        -2.9414e-01,  1.4728e-01,  1.8977e-01, -5.1791e-01,  3.6986e-01,\n",
            "         7.4582e-01,  8.2689e-02, -7.2601e-01, -4.0939e-01, -9.7822e-02,\n",
            "        -1.4096e-01,  7.1121e-01,  6.1933e-01, -2.5014e-01,  4.2250e-01,\n",
            "         4.8458e-01, -5.1915e-01,  7.7125e-01,  3.6685e-01,  4.9652e-01,\n",
            "        -4.1298e-02, -1.4683e+00,  2.0038e-01,  1.8591e-01,  4.9860e-02,\n",
            "        -1.7523e-01, -3.5528e-01,  9.4153e-01, -1.1898e-01, -5.1903e-01,\n",
            "        -1.1887e-02, -3.9186e-01, -1.7479e-01,  9.3451e-01, -5.8931e-01,\n",
            "        -2.7701e+00,  3.4522e-01,  8.6533e-01,  1.0808e+00, -1.0291e-01,\n",
            "        -9.1220e-02,  5.5092e-01, -3.9473e-01,  5.3676e-01,  1.0383e+00,\n",
            "        -4.0658e-01,  2.4590e-01, -2.6797e-01, -2.6036e-01, -1.4151e-01,\n",
            "        -1.2022e-01,  1.6234e-01, -7.4320e-01, -6.4728e-01,  4.7133e-02,\n",
            "         5.1642e-01,  1.9898e-01,  2.3919e-01,  1.2550e-01,  2.2471e-01,\n",
            "         8.2613e-01,  7.8328e-02, -5.7020e-01,  2.3934e-02, -1.5410e-01,\n",
            "        -2.5739e-01,  4.1262e-01, -4.6967e-01,  8.7914e-01,  7.2629e-01,\n",
            "         5.3862e-02, -1.1575e+00, -4.7835e-01,  2.0139e-01, -1.0051e+00,\n",
            "         1.1515e-01, -9.6609e-01,  1.2960e-01,  1.8388e-01, -3.0383e-02])\n",
            "\n",
            " Token: 5 .\n",
            "tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838,  0.0380,  0.1713,  0.1598,\n",
            "         0.4662, -0.0192,  0.4148, -0.3435,  0.2687,  0.0446,  0.4213, -0.4103,\n",
            "         0.1546,  0.0222, -0.6465,  0.2526,  0.0431, -0.1945,  0.4652,  0.4565,\n",
            "         0.6859,  0.0913,  0.2188, -0.7035,  0.1679, -0.3508, -0.1263,  0.6638,\n",
            "        -0.2582,  0.0365, -0.1361,  0.4025,  0.1429,  0.3813, -0.1228, -0.4589,\n",
            "        -0.2528, -0.3043, -0.1121, -0.2618, -0.2248, -0.4455,  0.2991, -0.8561,\n",
            "        -0.1450, -0.4909,  0.0083, -0.1749,  0.2752,  1.4401, -0.2124, -2.8435,\n",
            "        -0.2796, -0.4572,  1.6386,  0.7881, -0.5526,  0.6500,  0.0864,  0.3901,\n",
            "         1.0632, -0.3538,  0.4833,  0.3460,  0.8417,  0.0987, -0.2421, -0.2705,\n",
            "         0.0453, -0.4015,  0.1139,  0.0062,  0.0367,  0.0185, -1.0213, -0.2081,\n",
            "         0.6407, -0.0688, -0.5864,  0.3348, -1.1432, -0.1148, -0.2509, -0.4591,\n",
            "        -0.0968, -0.1795, -0.0634, -0.6741, -0.0689,  0.5360, -0.8777,  0.3180,\n",
            "        -0.3924, -0.2339,  0.4730, -0.0288])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCBamRMU4mf_"
      },
      "source": [
        "## **Document Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73QVRiYY4rjX",
        "outputId": "6a2726e8-f8bd-460d-ba9a-d01e3eb1ea72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.data import Sentence\n",
        "\n",
        "glove_embeddings = WordEmbeddings('glove')\n",
        "\n",
        "document_embeddings = DocumentRNNEmbeddings([glove_embedding])\n",
        "\n",
        "# create an example sentence\n",
        "sentence = Sentence('The grass is green and the sky is blue.')\n",
        "\n",
        "# embed the sentence with our document embedding\n",
        "document_embeddings.embed(sentence)\n",
        "\n",
        "# now check out the embedded sentence.\n",
        "print(sentence.get_embedding())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.0440, -0.3109, -0.0417,  0.0755,  0.0792, -0.0844, -0.0824, -0.1984,\n",
            "        -0.0606,  0.1573,  0.0708, -0.0084,  0.2063,  0.1378, -0.2152, -0.0593,\n",
            "         0.1882, -0.2069, -0.0904,  0.1662,  0.1048,  0.0437,  0.3212, -0.2128,\n",
            "         0.1258, -0.1650, -0.0848,  0.1415, -0.1952, -0.1981,  0.0882, -0.2492,\n",
            "        -0.2923,  0.1543, -0.1051,  0.4094,  0.0007,  0.4009, -0.4420, -0.3354,\n",
            "        -0.0406,  0.0440,  0.1490,  0.0344,  0.0982,  0.0837, -0.0094, -0.1453,\n",
            "        -0.3861, -0.2928,  0.1424, -0.4047,  0.1599,  0.3470, -0.2107,  0.6693,\n",
            "         0.0171,  0.2365, -0.0158, -0.0753,  0.0235,  0.1951,  0.2331, -0.1688,\n",
            "        -0.3832, -0.4519,  0.1698,  0.1330, -0.2802,  0.0750, -0.0335, -0.0565,\n",
            "         0.1637, -0.0454,  0.1202, -0.2097,  0.2553, -0.0944,  0.1900, -0.1798,\n",
            "        -0.0650, -0.3736,  0.1023, -0.3984,  0.2873, -0.1591, -0.2093, -0.1043,\n",
            "         0.3362, -0.4446,  0.0269, -0.3394,  0.1413,  0.0803,  0.2299,  0.2608,\n",
            "        -0.3816,  0.2213,  0.2121, -0.1286, -0.2741,  0.1569, -0.1274, -0.1786,\n",
            "         0.1418,  0.3573, -0.0723,  0.4255, -0.3519, -0.0149, -0.2035, -0.1433,\n",
            "         0.2887, -0.1107,  0.0558,  0.0655,  0.1369,  0.1460, -0.3024,  0.1476,\n",
            "         0.1034,  0.1163,  0.3566, -0.0436,  0.1996,  0.3151, -0.2914,  0.1205],\n",
            "       grad_fn=<CatBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjTHilbxKecl"
      },
      "source": [
        "## **Loading training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xkQhLGdKiWA",
        "outputId": "5909781a-bb5e-4655-eb47-eb98f974fe4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# the corpus represents a dataset that is used to train a model \n",
        "# It consists of a list of train sentences, a list of developement sentences and a list of test sentences\n",
        "import flair.datasets\n",
        "\n",
        "corpus = flair.datasets.UD_ENGLISH()\n",
        "\n",
        "# print number of sentences in the train split\n",
        "print('\\nnumber of sentences in traing split is ', len(corpus.train),'\\n')\n",
        "\n",
        "# print number of sentences in the test split\n",
        "print('number of sentences in testing split is ', len(corpus.test),'\\n')\n",
        "\n",
        "# print number of sentences in the developement split\n",
        "print('number of sentences in development split is ',len(corpus.dev),'\\n')\n",
        "\n",
        "# print the second sentence in the training split\n",
        "print('the second sentence in the training split is ', corpus.train[1], '\\n')\n",
        "\n",
        "# print the first sentence in the test split\n",
        "print('the first sentence in the test split with POS tagging is ', corpus.test[0].to_tagged_string('pos'), '\\n')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-01 19:08:25,647 Reading data from /root/.flair/datasets/ud_english\n",
            "2020-11-01 19:08:25,649 Train: /root/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
            "2020-11-01 19:08:25,651 Dev: /root/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
            "2020-11-01 19:08:25,655 Test: /root/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n",
            "\n",
            "number of sentences in traing split is  12543 \n",
            "\n",
            "number of sentences in testing split is  2077 \n",
            "\n",
            "number of sentences in development split is  2002 \n",
            "\n",
            "the second sentence in the training split is  Sentence: \"[ This killing of a respected cleric will be causing us trouble for years to come . ]\"   [− Tokens: 18  − Token-Labels: \"[ <[/PUNCT/-LRB-/punct> This <this/DET/DT/det/Sing/Dem> killing <killing/NOUN/NN/nsubj/Sing> of <of/ADP/IN/case> a <a/DET/DT/det/Ind/Art> respected <respected/ADJ/JJ/amod/Pos> cleric <cleric/NOUN/NN/nmod/Sing> will <will/AUX/MD/aux/Fin> be <be/AUX/VB/aux/Inf> causing <cause/VERB/VBG/root/Ger> us <we/PRON/PRP/iobj/Acc/Plur/1/Prs> trouble <trouble/NOUN/NN/obj/Sing> for <for/ADP/IN/case> years <year/NOUN/NNS/obl/Plur> to <to/PART/TO/mark> come <come/VERB/VB/acl/Inf> . <./PUNCT/./punct> ] <]/PUNCT/-RRB-/punct>\"] \n",
            "\n",
            "the first sentence in the test split with POS tagging is  What <WP> if <IN> Google <NNP> Morphed <VBD> Into <IN> GoogleOS <NNP> ? <.> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}